
# Iris Flower Classification

This project is focused on classifying the Iris flower species using various machine learning models. The models used include K-Nearest Neighbors, Decision Trees, Random Forest, AdaBoost, Support Vector Machine, Logistic Regression, CatBoost, and XGBoost.

## Table of Contents

- [Introduction](#introduction)
- [Dataset](#dataset)
- [Installation](#installation)
- [Models Used](#models-used)
- [Evaluation Metrics](#evaluation-metrics)
- [Results](#results)
- [Acknowledgements](#acknowledgements)

## Introduction

The Iris flower classification project aims to classify the Iris flower species into three categories: Iris-setosa, Iris-versicolour, and Iris-virginica. The dataset contains 150 samples, with 50 samples for each species. Each sample has four features: sepal length, sepal width, petal length, and petal width.

## Dataset

The dataset used in this project is the Iris dataset, which is a well-known dataset in the machine learning community. The dataset is loaded using the `sklearn.datasets` module.

## Installation

To run this project, you need to have Python installed along with the following libraries:
- pandas
- numpy
- matplotlib
- scikit-learn
- catboost
- xgboost

You can install the required libraries using pip:

```sh
pip install pandas numpy matplotlib scikit-learn catboost xgboost
```

## Models Used

The following models were used in this project:
- K-Nearest Neighbors
- Decision Tree
- Random Forest
- AdaBoost
- Support Vector Machine
- Logistic Regression
- CatBoost
- XGBoost

## Evaluation Metrics

The performance of the models was evaluated using the following metrics:
- Accuracy
- Precision
- Recall
- F1 Score

## Results

The results of the models will be displayed here after running the evaluations. Each model's performance can be compared based on the evaluation metrics listed above.

## Acknowledgements

This project was completed as part of the Let's Grow More Virtual Internship Program. Special thanks to the Let's Grow More team for providing this opportunity.

---
